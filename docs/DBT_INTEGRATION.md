# ğŸ”— Ğ˜Ğ½Ñ‚ĞµĞ³Ñ€Ğ°Ñ†Ğ¸Ñ dbt Ñ ClickHouse

## ĞĞ±Ğ·Ğ¾Ñ€

ClickHouse EnergyHub Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞµÑ‚ **dbt (data build tool)** Ğ´Ğ»Ñ Ñ‚Ñ€Ğ°Ğ½ÑÑ„Ğ¾Ñ€Ğ¼Ğ°Ñ†Ğ¸Ğ¸ Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ… Ğ² ClickHouse. Ğ­Ñ‚Ğ° Ğ¸Ğ½Ñ‚ĞµĞ³Ñ€Ğ°Ñ†Ğ¸Ñ Ğ¾Ğ±ĞµÑĞ¿ĞµÑ‡Ğ¸Ğ²Ğ°ĞµÑ‚ Ğ´ĞµĞºĞ»Ğ°Ñ€Ğ°Ñ‚Ğ¸Ğ²Ğ½Ñ‹Ğ¹ Ğ¿Ğ¾Ğ´Ñ…Ğ¾Ğ´ Ğº ÑĞ¾Ğ·Ğ´Ğ°Ğ½Ğ¸Ñ Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹ Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ…, Ğ°Ğ²Ñ‚Ğ¾Ğ¼Ğ°Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ¾Ğµ Ñ‚ĞµÑÑ‚Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ Ğ¸ Ğ´Ğ¾ĞºÑƒĞ¼ĞµĞ½Ñ‚Ğ°Ñ†Ğ¸Ñ.

## ğŸ—ï¸ ĞÑ€Ñ…Ğ¸Ñ‚ĞµĞºÑ‚ÑƒÑ€Ğ° Ğ¸Ğ½Ñ‚ĞµĞ³Ñ€Ğ°Ñ†Ğ¸Ğ¸

### ĞšĞ¾Ğ¼Ğ¿Ğ¾Ğ½ĞµĞ½Ñ‚Ñ‹ ÑĞ¸ÑÑ‚ĞµĞ¼Ñ‹

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   ClickHouse    â”‚    â”‚      dbt        â”‚    â”‚     Airflow     â”‚
â”‚                 â”‚    â”‚                 â”‚    â”‚                 â”‚
â”‚ â€¢ Raw Tables    â”‚â—„â”€â”€â”€â”¤ â€¢ Models        â”‚â—„â”€â”€â”€â”¤ â€¢ DAGs          â”‚
â”‚ â€¢ ODS Tables    â”‚    â”‚ â€¢ Tests         â”‚    â”‚ â€¢ Scheduling    â”‚
â”‚ â€¢ DDS Tables    â”‚    â”‚ â€¢ Sources       â”‚    â”‚ â€¢ Monitoring    â”‚
â”‚ â€¢ CDM Tables    â”‚    â”‚ â€¢ Macros        â”‚    â”‚ â€¢ Logs          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### ĞŸĞ¾Ñ‚Ğ¾Ğº Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ…

```
1. ClickHouse Tables â†’ 2. dbt Sources â†’ 3. dbt Models â†’ 4. ClickHouse Tables
     â†“                       â†“              â†“              â†“
  Data Storage         Metadata        Transformation   Processed Data
```

## ğŸ“ Ğ¡Ñ‚Ñ€ÑƒĞºÑ‚ÑƒÑ€Ğ° Ğ¿Ñ€Ğ¾ĞµĞºÑ‚Ğ° dbt

```
dbt/
â”œâ”€â”€ dbt_project.yml          # ĞšĞ¾Ğ½Ñ„Ğ¸Ğ³ÑƒÑ€Ğ°Ñ†Ğ¸Ñ Ğ¿Ñ€Ğ¾ĞµĞºÑ‚Ğ°
â”œâ”€â”€ profiles.yml             # ĞŸÑ€Ğ¾Ñ„Ğ¸Ğ»Ğ¸ Ğ¿Ğ¾Ğ´ĞºĞ»ÑÑ‡ĞµĞ½Ğ¸Ñ
â”œâ”€â”€ packages.yml             # Ğ—Ğ°Ğ²Ğ¸ÑĞ¸Ğ¼Ğ¾ÑÑ‚Ğ¸
â”œâ”€â”€ models/                  # ĞœĞ¾Ğ´ĞµĞ»Ğ¸ Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ…
â”‚   â”œâ”€â”€ sources.yml          # ĞĞ¿Ñ€ĞµĞ´ĞµĞ»ĞµĞ½Ğ¸Ğµ Ğ¸ÑÑ‚Ğ¾Ñ‡Ğ½Ğ¸ĞºĞ¾Ğ²
â”‚   â”œâ”€â”€ raw/                 # ĞœĞ¾Ğ´ĞµĞ»Ğ¸ Ğ´Ğ»Ñ raw ÑĞ»Ğ¾Ñ
â”‚   â”œâ”€â”€ ods/                 # ĞœĞ¾Ğ´ĞµĞ»Ğ¸ Ğ´Ğ»Ñ ODS ÑĞ»Ğ¾Ñ
â”‚   â”œâ”€â”€ dds/                 # ĞœĞ¾Ğ´ĞµĞ»Ğ¸ Ğ´Ğ»Ñ DDS ÑĞ»Ğ¾Ñ
â”‚   â””â”€â”€ cdm/                 # ĞœĞ¾Ğ´ĞµĞ»Ğ¸ Ğ´Ğ»Ñ CDM ÑĞ»Ğ¾Ñ
â”œâ”€â”€ tests/                   # ĞšĞ°ÑÑ‚Ğ¾Ğ¼Ğ½Ñ‹Ğµ Ñ‚ĞµÑÑ‚Ñ‹
â”œâ”€â”€ macros/                  # ĞœĞ°ĞºÑ€Ğ¾ÑÑ‹
â”œâ”€â”€ seeds/                   # Ğ¡Ñ‚Ğ°Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ¸Ğµ Ğ´Ğ°Ğ½Ğ½Ñ‹Ğµ
â””â”€â”€ target/                  # Ğ¡ĞºĞ¾Ğ¼Ğ¿Ğ¸Ğ»Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½Ñ‹Ğµ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸
```

## âš™ï¸ ĞšĞ¾Ğ½Ñ„Ğ¸Ğ³ÑƒÑ€Ğ°Ñ†Ğ¸Ñ

### dbt_project.yml

```yaml
name: 'clickhouse_energyhub'
version: '1.0.0'
config-version: 2

profile: 'clickhouse_energyhub'

model-paths: ["models"]
analysis-paths: ["analyses"]
test-paths: ["tests"]
seed-paths: ["seeds"]
macro-paths: ["macros"]
snapshot-paths: ["snapshots"]

target-path: "target"
clean-targets:
  - "target"
  - "dbt_packages"

models:
  clickhouse_energyhub:
    materialized: table
    raw:
      materialized: table
      tags: ["raw"]
    ods:
      materialized: table
      tags: ["ods"]
    dds:
      materialized: table
      tags: ["dds"]
    cdm:
      materialized: table
      tags: ["cdm"]

vars:
  clickhouse_database: "default"
  clickhouse_cluster: "clickhouse_cluster"
```

### profiles.yml

```yaml
clickhouse_energyhub:
  target: dev
  outputs:
    dev:
      type: clickhouse
      host: clickhouse-01
      port: 9000
      user: <Ğ²Ğ°Ñˆ_super_user_name>
      password: <Ğ²Ğ°Ñˆ_super_user_password>
      database: default
      schema: default
      threads: 4
      keepalives_idle: 0
      connect_timeout: 10
      send_receive_timeout: 300
      sync_request_timeout: 5
      compression: True
      secure: False
      verify: False
      client_name: dbt
      settings:
        optimize_aggregation_in_order: 1
        max_threads: 8
        max_memory_usage: 8589934592
```

### packages.yml

```yaml
packages:
  - package: dbt-labs/dbt_utils
    version: 1.1.1
  - package: dbt-labs/audit_helper
    version: 0.9.0
  - package: metaplane/dbt_expectations
    version: 0.10.4
  - package: godatadriven/dbt_date
    version: 0.10.1
```

## ğŸ—ï¸ ĞœĞ¾Ğ´ĞµĞ»Ğ¸ Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ…

### Ğ¢Ğ¸Ğ¿Ñ‹ Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹

#### 1. **Raw Models** (Ğ¡Ñ‹Ñ€Ñ‹Ğµ Ğ´Ğ°Ğ½Ğ½Ñ‹Ğµ)
```sql
-- models/raw/raw_river_flow.sql
{{
  config(
    materialized='table',
    tags=['raw', 'river_flow']
  )
}}

SELECT 
  ges_name,
  timestamp,
  river_name,
  water_level_m,
  flow_rate_m3_s,
  power_output_mw,
  now() as loaded_at
FROM {{ source('raw', 'river_flow') }}
WHERE timestamp >= '{{ var("start_date", "2020-01-01") }}'
```

#### 2. **ODS Models** (ĞĞ¿ĞµÑ€Ğ°Ñ†Ğ¸Ğ¾Ğ½Ğ½Ñ‹Ğµ Ğ´Ğ°Ğ½Ğ½Ñ‹Ğµ)
```sql
-- models/ods/ods_river_flow.sql
{{
  config(
    materialized='table',
    tags=['ods', 'river_flow']
  )
}}

SELECT 
  ges_name,
  timestamp,
  river_name,
  CAST(water_level_m AS Float64) as water_level_m,
  CAST(flow_rate_m3_s AS Float64) as flow_rate_m3_s,
  CAST(power_output_mw AS Float64) as power_output_mw,
  now() as processed_at
FROM {{ ref('raw_river_flow') }}
WHERE ges_name IS NOT NULL
  AND timestamp IS NOT NULL
  AND river_name IS NOT NULL
```

#### 3. **DDS Models** (Ğ”ĞµÑ‚Ğ°Ğ»Ğ¸Ğ·Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½Ñ‹Ğµ Ğ´Ğ°Ğ½Ğ½Ñ‹Ğµ)
```sql
-- models/dds/dds_river_flow_clean.sql
{{
  config(
    materialized='table',
    tags=['dds', 'river_flow', 'clean']
  )
}}

WITH deduplicated_river_flow AS (
  SELECT 
    ges_name,
    timestamp,
    river_name,
    water_level_m,
    flow_rate_m3_s,
    power_output_mw,
    ROW_NUMBER() OVER (
      PARTITION BY ges_name, timestamp, river_name 
      ORDER BY timestamp DESC
    ) as rn
  FROM {{ source('raw', 'river_flow') }}
  WHERE ges_name IS NOT NULL 
    AND timestamp IS NOT NULL 
    AND river_name IS NOT NULL
)

SELECT 
  ges_name,
  timestamp,
  river_name,
  water_level_m,
  flow_rate_m3_s,
  power_output_mw,
  now() as inserted_at,
  'dbt_clean' as source
FROM deduplicated_river_flow
WHERE rn = 1
```

#### 4. **CDM Models** (ĞšĞ¾Ğ½Ñ„Ğ¾Ñ€Ğ¼Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½Ñ‹Ğµ Ğ´Ğ°Ğ½Ğ½Ñ‹Ğµ)
```sql
-- models/cdm/cdm_daily_river_flow_summary.sql
{{
  config(
    materialized='table',
    tags=['cdm', 'river_flow', 'summary']
  )
}}

SELECT 
  toDate(timestamp) as date,
  ges_name,
  river_name,
  COUNT(*) as record_count,
  AVG(water_level_m) as avg_water_level,
  AVG(flow_rate_m3_s) as avg_flow_rate,
  AVG(power_output_mw) as avg_power_output,
  MAX(water_level_m) as max_water_level,
  MIN(water_level_m) as min_water_level,
  now() as calculated_at
FROM {{ ref('dds_river_flow_clean') }}
GROUP BY toDate(timestamp), ges_name, river_name
ORDER BY date DESC, ges_name, river_name
```

### View Models

```sql
-- models/dds/dds_river_flow_view.sql
{{
  config(
    materialized='view',
    tags=['dds', 'river_flow', 'view']
  )
}}

SELECT 
  ges_name,
  timestamp,
  river_name,
  water_level_m,
  flow_rate_m3_s,
  power_output_mw,
  inserted_at,
  source
FROM {{ ref('dds_river_flow_clean') }}
WHERE inserted_at >= now() - INTERVAL 30 DAY
```

## ğŸ§ª Ğ¢ĞµÑÑ‚Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ

### ĞĞ²Ñ‚Ğ¾Ğ¼Ğ°Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ¸Ğµ Ñ‚ĞµÑÑ‚Ñ‹

#### 1. **Generic Tests** (Ğ’ÑÑ‚Ñ€Ğ¾ĞµĞ½Ğ½Ñ‹Ğµ Ñ‚ĞµÑÑ‚Ñ‹)
```yaml
# models/dds/schema.yml
version: 2

models:
  - name: dds_river_flow_clean
    description: "ĞÑ‡Ğ¸Ñ‰ĞµĞ½Ğ½Ñ‹Ğµ Ğ´Ğ°Ğ½Ğ½Ñ‹Ğµ river_flow Ğ±ĞµĞ· Ğ´ÑƒĞ±Ğ»ĞµĞ¹"
    columns:
      - name: ges_name
        description: "ĞĞ°Ğ·Ğ²Ğ°Ğ½Ğ¸Ğµ Ğ“Ğ­Ğ¡"
        tests:
          - not_null
          - dbt_utils.not_empty_string
      
      - name: timestamp
        description: "Ğ’Ñ€ĞµĞ¼ĞµĞ½Ğ½Ğ°Ñ Ğ¼ĞµÑ‚ĞºĞ°"
        tests:
          - not_null
      
      - name: water_level_m
        description: "Ğ£Ñ€Ğ¾Ğ²ĞµĞ½ÑŒ Ğ²Ğ¾Ğ´Ñ‹ Ğ² Ğ¼ĞµÑ‚Ñ€Ğ°Ñ…"
        tests:
          - not_null
          - dbt_utils.accepted_range:
              min_value: 0
              max_value: 1000
```

#### 2. **Custom Tests** (ĞšĞ°ÑÑ‚Ğ¾Ğ¼Ğ½Ñ‹Ğµ Ñ‚ĞµÑÑ‚Ñ‹)
```sql
-- tests/test_no_duplicates.sql
SELECT 
  ges_name,
  timestamp,
  river_name,
  COUNT(*) as record_count
FROM {{ ref('dds_river_flow_clean') }}
GROUP BY ges_name, timestamp, river_name
HAVING COUNT(*) > 1
```

#### 3. **Data Tests** (Ğ¢ĞµÑÑ‚Ñ‹ Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ…)
```sql
-- tests/test_data_quality.sql
SELECT 
  'water_level_out_of_range' as test_name,
  COUNT(*) as failed_records
FROM {{ ref('dds_river_flow_clean') }}
WHERE water_level_m < 0 OR water_level_m > 1000

UNION ALL

SELECT 
  'flow_rate_out_of_range' as test_name,
  COUNT(*) as failed_records
FROM {{ ref('dds_river_flow_clean') }}
WHERE flow_rate_m3_s < 0 OR flow_rate_m3_s > 10000
```

### Ğ—Ğ°Ğ¿ÑƒÑĞº Ñ‚ĞµÑÑ‚Ğ¾Ğ²

```bash
# Ğ’ÑĞµ Ñ‚ĞµÑÑ‚Ñ‹
dbt test

# Ğ¢ĞµÑÑ‚Ñ‹ Ğ´Ğ»Ñ ĞºĞ¾Ğ½ĞºÑ€ĞµÑ‚Ğ½Ğ¾Ğ¹ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸
dbt test --select dds_river_flow_clean

# Ğ¢ĞµÑÑ‚Ñ‹ Ğ´Ğ»Ñ ĞºĞ¾Ğ½ĞºÑ€ĞµÑ‚Ğ½Ğ¾Ğ³Ğ¾ Ñ‚ĞµĞ³Ğ°
dbt test --select tag:clean

# ĞšĞ°ÑÑ‚Ğ¾Ğ¼Ğ½Ñ‹Ğµ Ñ‚ĞµÑÑ‚Ñ‹
dbt test --select test_no_duplicates
```

## ğŸ”„ Ğ˜ÑÑ‚Ğ¾Ñ‡Ğ½Ğ¸ĞºĞ¸ Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ…

### ĞĞ²Ñ‚Ğ¾Ğ¼Ğ°Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ¾Ğµ Ğ¾Ğ±Ğ½Ğ¾Ğ²Ğ»ĞµĞ½Ğ¸Ğµ sources.yml

Ğ¡Ğ¸ÑÑ‚ĞµĞ¼Ğ° Ğ°Ğ²Ñ‚Ğ¾Ğ¼Ğ°Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ¸ Ğ¾Ğ±Ğ½Ğ¾Ğ²Ğ»ÑĞµÑ‚ `sources.yml` Ğ½Ğ° Ğ¾ÑĞ½Ğ¾Ğ²Ğµ Ñ‚Ğ°Ğ±Ğ»Ğ¸Ñ† Ğ² ClickHouse:

```yaml
# models/sources.yml (Ğ°Ğ²Ñ‚Ğ¾Ğ¼Ğ°Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ¸ Ğ³ĞµĞ½ĞµÑ€Ğ¸Ñ€ÑƒĞµÑ‚ÑÑ)
version: 2

sources:
  - name: raw
    description: "Tables from raw database"
    database: raw
    schema: raw
    tables:
      - name: river_flow
        description: "Raw river flow data"
        columns:
          - name: ges_name
            description: "Name of the hydroelectric power station"
            tests:
              - not_null
          - name: timestamp
            description: "Measurement timestamp"
            tests:
              - not_null
          # ... Ğ´Ñ€ÑƒĞ³Ğ¸Ğµ ĞºĞ¾Ğ»Ğ¾Ğ½ĞºĞ¸
```

### Ğ ÑƒÑ‡Ğ½Ğ¾Ğµ Ğ¾Ğ¿Ñ€ĞµĞ´ĞµĞ»ĞµĞ½Ğ¸Ğµ Ğ¸ÑÑ‚Ğ¾Ñ‡Ğ½Ğ¸ĞºĞ¾Ğ²

```yaml
# models/sources.yml (Ñ€ÑƒÑ‡Ğ½Ğ¾Ğµ Ğ¾Ğ¿Ñ€ĞµĞ´ĞµĞ»ĞµĞ½Ğ¸Ğµ)
version: 2

sources:
  - name: external_api
    description: "External API data sources"
    tables:
      - name: weather_data
        description: "Weather information from external API"
        columns:
          - name: timestamp
            description: "Weather measurement time"
            tests:
              - not_null
          - name: temperature
            description: "Temperature in Celsius"
            tests:
              - not_null
              - dbt_utils.accepted_range:
                  min_value: -50
                  max_value: 60
```

## ğŸ¯ ĞœĞ°ĞºÑ€Ğ¾ÑÑ‹

### ĞŸĞ¾Ğ»ĞµĞ·Ğ½Ñ‹Ğµ Ğ¼Ğ°ĞºÑ€Ğ¾ÑÑ‹ Ğ´Ğ»Ñ ClickHouse

#### 1. **ĞŸĞ°Ñ€Ñ‚Ğ¸Ñ†Ğ¸Ğ¾Ğ½Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ Ğ¿Ğ¾ Ğ²Ñ€ĞµĞ¼ĞµĞ½Ğ¸**
```sql
-- macros/partition_by_time.sql
{% macro partition_by_time(column_name) %}
  PARTITION BY toYYYYMM({{ column_name }})
{% endmacro %}
```

#### 2. **ĞĞ¿Ñ‚Ğ¸Ğ¼Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ Ğ´Ğ»Ñ ClickHouse**
```sql
-- macros/clickhouse_optimize.sql
{% macro clickhouse_optimize() %}
  OPTIMIZE TABLE {{ this }} FINAL
{% endmacro %}
```

#### 3. **Ğ“ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ñ Ğ´Ğ°Ñ‚**
```sql
-- macros/generate_date_spine.sql
{% macro generate_date_spine(datepart, start_date, end_date) %}
  SELECT 
    toDate(date) as date
  FROM (
    SELECT 
      toDate('{{ start_date }}') + INTERVAL number DAY as date
    FROM numbers(
      dateDiff('day', '{{ start_date }}', '{{ end_date }}') + 1
    )
  )
{% endmacro %}
```

### Ğ˜ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ Ğ¼Ğ°ĞºÑ€Ğ¾ÑĞ¾Ğ²

```sql
-- models/cdm/cdm_daily_summary.sql
{{
  config(
    materialized='table',
    tags=['cdm', 'summary']
  )
}}

SELECT 
  d.date,
  COUNT(r.record_id) as record_count
FROM {{ generate_date_spine('day', '2020-01-01', '2024-12-31') }} d
LEFT JOIN {{ ref('raw_records') }} r ON toDate(r.timestamp) = d.date
GROUP BY d.date
ORDER BY d.date
```

## ğŸ“Š Ğ”Ğ¾ĞºÑƒĞ¼ĞµĞ½Ñ‚Ğ°Ñ†Ğ¸Ñ

### Ğ“ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ñ Ğ´Ğ¾ĞºÑƒĞ¼ĞµĞ½Ñ‚Ğ°Ñ†Ğ¸Ğ¸

```bash
# Ğ“ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ñ Ğ´Ğ¾ĞºÑƒĞ¼ĞµĞ½Ñ‚Ğ°Ñ†Ğ¸Ğ¸
dbt docs generate

# Ğ—Ğ°Ğ¿ÑƒÑĞº Ğ²ĞµĞ±-ÑĞµÑ€Ğ²ĞµÑ€Ğ° Ğ´Ğ¾ĞºÑƒĞ¼ĞµĞ½Ñ‚Ğ°Ñ†Ğ¸Ğ¸
dbt docs serve --port 8080
```

### Ğ¡Ñ‚Ñ€ÑƒĞºÑ‚ÑƒÑ€Ğ° Ğ´Ğ¾ĞºÑƒĞ¼ĞµĞ½Ñ‚Ğ°Ñ†Ğ¸Ğ¸

```
ğŸ“š dbt Documentation
â”œâ”€â”€ ğŸ  Home
â”œâ”€â”€ ğŸ“ Models
â”‚   â”œâ”€â”€ Raw Layer
â”‚   â”œâ”€â”€ ODS Layer
â”‚   â”œâ”€â”€ DDS Layer
â”‚   â””â”€â”€ CDM Layer
â”œâ”€â”€ ğŸ”— Sources
â”œâ”€â”€ ğŸ§ª Tests
â”œâ”€â”€ ğŸ“Š Lineage Graph
â””â”€â”€ ğŸ“ˆ DAG View
```

## ğŸš€ Ğ˜Ğ½Ñ‚ĞµĞ³Ñ€Ğ°Ñ†Ğ¸Ñ Ñ Airflow

### DAG Ğ´Ğ»Ñ dbt

```python
# airflow/dags/dbt_pipeline.py
from airflow import DAG
from airflow.operators.bash import BashOperator
from datetime import datetime, timedelta

default_args = {
    'owner': 'energy-hub',
    'depends_on_past': False,
    'start_date': datetime(2025, 1, 1),
    'email_on_failure': False,
    'email_on_retry': False,
    'retries': 2,
    'retry_delay': timedelta(minutes=5),
}

dag = DAG(
    'dbt_pipeline',
    default_args=default_args,
    description='dbt data transformation pipeline',
    schedule='0 */2 * * *',  # ĞšĞ°Ğ¶Ğ´Ñ‹Ğµ 2 Ñ‡Ğ°ÑĞ°
    catchup=False,
)

# Ğ—Ğ°Ğ´Ğ°Ñ‡Ğ¸ dbt
run_models = BashOperator(
    task_id='run_dbt_models',
    bash_command='cd /opt/airflow/dbt && dbt run',
    dag=dag,
)

run_tests = BashOperator(
    task_id='run_dbt_tests',
    bash_command='cd /opt/airflow/dbt && dbt test',
    dag=dag,
)

generate_docs = BashOperator(
    task_id='generate_dbt_docs',
    bash_command='cd /opt/airflow/dbt && dbt docs generate',
    dag=dag,
)

# Ğ—Ğ°Ğ²Ğ¸ÑĞ¸Ğ¼Ğ¾ÑÑ‚Ğ¸
run_models >> run_tests >> generate_docs
```

### ĞœĞ¾Ğ½Ğ¸Ñ‚Ğ¾Ñ€Ğ¸Ğ½Ğ³ Ğ² Airflow

- **Ğ›Ğ¾Ğ³Ğ¸ Ğ²Ñ‹Ğ¿Ğ¾Ğ»Ğ½ĞµĞ½Ğ¸Ñ** ĞºĞ°Ğ¶Ğ´Ğ¾Ğ¹ dbt ĞºĞ¾Ğ¼Ğ°Ğ½Ğ´Ñ‹
- **Ğ’Ñ€ĞµĞ¼Ñ Ğ²Ñ‹Ğ¿Ğ¾Ğ»Ğ½ĞµĞ½Ğ¸Ñ** Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹
- **Ğ¡Ñ‚Ğ°Ñ‚ÑƒÑ Ñ‚ĞµÑÑ‚Ğ¾Ğ²** (PASS/FAIL)
- **Ğ£Ğ²ĞµĞ´Ğ¾Ğ¼Ğ»ĞµĞ½Ğ¸Ñ** Ğ¾Ğ± Ğ¾ÑˆĞ¸Ğ±ĞºĞ°Ñ…

## ğŸ”§ ĞĞ¿Ñ‚Ğ¸Ğ¼Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ Ğ¿Ñ€Ğ¾Ğ¸Ğ·Ğ²Ğ¾Ğ´Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ¾ÑÑ‚Ğ¸

### ClickHouse ÑĞ¿ĞµÑ†Ğ¸Ñ„Ğ¸Ñ‡Ğ½Ñ‹Ğµ Ğ½Ğ°ÑÑ‚Ñ€Ğ¾Ğ¹ĞºĞ¸

#### 1. **ĞŸĞ°Ñ€Ñ‚Ğ¸Ñ†Ğ¸Ğ¾Ğ½Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ**
```sql
-- ĞĞ¿Ñ‚Ğ¸Ğ¼Ğ°Ğ»ÑŒĞ½Ğ¾Ğµ Ğ¿Ğ°Ñ€Ñ‚Ğ¸Ñ†Ğ¸Ğ¾Ğ½Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ Ğ´Ğ»Ñ Ğ²Ñ€ĞµĞ¼ĞµĞ½Ğ½Ñ‹Ñ… Ñ€ÑĞ´Ğ¾Ğ²
PARTITION BY toYYYYMM(timestamp)
ORDER BY (timestamp, entity_id)
```

#### 2. **Ğ˜Ğ½Ğ´ĞµĞºÑÑ‹**
```sql
-- Ğ¡Ğ¾Ğ·Ğ´Ğ°Ğ½Ğ¸Ğµ Ğ¸Ğ½Ğ´ĞµĞºÑĞ¾Ğ² Ğ´Ğ»Ñ Ñ‡Ğ°ÑÑ‚Ğ¾ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞµĞ¼Ñ‹Ñ… ĞºĞ¾Ğ»Ğ¾Ğ½Ğ¾Ğº
ALTER TABLE dds_river_flow_clean 
ADD INDEX idx_ges_name ges_name TYPE bloom_filter GRANULARITY 1;
```

#### 3. **ĞœĞ°Ñ‚ĞµÑ€Ğ¸Ğ°Ğ»Ğ¸Ğ·Ğ¾Ğ²Ğ°Ğ½Ğ½Ñ‹Ğµ Ğ¿Ñ€ĞµĞ´ÑÑ‚Ğ°Ğ²Ğ»ĞµĞ½Ğ¸Ñ**
```sql
-- ĞĞ²Ñ‚Ğ¾Ğ¼Ğ°Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ¾Ğµ Ğ¾Ğ±Ğ½Ğ¾Ğ²Ğ»ĞµĞ½Ğ¸Ğµ Ğ°Ğ³Ñ€ĞµĞ³Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½Ñ‹Ñ… Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ…
CREATE MATERIALIZED VIEW cdm_daily_summary_mv
ENGINE = SummingMergeTree()
PARTITION BY toYYYYMM(date)
ORDER BY (date, ges_name)
AS SELECT 
    toDate(timestamp) as date,
    ges_name,
    COUNT(*) as record_count,
    AVG(water_level_m) as avg_water_level
FROM dds_river_flow_clean
GROUP BY date, ges_name;
```

### dbt Ğ¾Ğ¿Ñ‚Ğ¸Ğ¼Ğ¸Ğ·Ğ°Ñ†Ğ¸Ğ¸

#### 1. **Ğ˜Ğ½ĞºÑ€ĞµĞ¼ĞµĞ½Ñ‚Ğ°Ğ»ÑŒĞ½Ñ‹Ğµ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸**
```sql
-- models/dds/dds_river_flow_incremental.sql
{{
  config(
    materialized='incremental',
    unique_key='id',
    incremental_strategy='delete+insert'
  )
}}

SELECT 
  id,
  ges_name,
  timestamp,
  -- ... Ğ´Ñ€ÑƒĞ³Ğ¸Ğµ ĞºĞ¾Ğ»Ğ¾Ğ½ĞºĞ¸
FROM {{ source('raw', 'river_flow') }}

{% if is_incremental() %}
  WHERE timestamp > (SELECT MAX(timestamp) FROM {{ this }})
{% endif %}
```

#### 2. **ĞŸĞ°Ñ€Ğ°Ğ»Ğ»ĞµĞ»ÑŒĞ½Ğ¾Ğµ Ğ²Ñ‹Ğ¿Ğ¾Ğ»Ğ½ĞµĞ½Ğ¸Ğµ**
```yaml
# dbt_project.yml
threads: 8  # ĞšĞ¾Ğ»Ğ¸Ñ‡ĞµÑÑ‚Ğ²Ğ¾ Ğ¿Ğ°Ñ€Ğ°Ğ»Ğ»ĞµĞ»ÑŒĞ½Ñ‹Ñ… Ğ¿Ğ¾Ñ‚Ğ¾ĞºĞ¾Ğ²
```

## ğŸš¨ Ğ£ÑÑ‚Ñ€Ğ°Ğ½ĞµĞ½Ğ¸Ğµ Ğ½ĞµĞ¿Ğ¾Ğ»Ğ°Ğ´Ğ¾Ğº

### Ğ§Ğ°ÑÑ‚Ñ‹Ğµ Ğ¿Ñ€Ğ¾Ğ±Ğ»ĞµĞ¼Ñ‹

#### 1. **ĞÑˆĞ¸Ğ±ĞºĞ¸ Ğ¿Ğ¾Ğ´ĞºĞ»ÑÑ‡ĞµĞ½Ğ¸Ñ Ğº ClickHouse**
```bash
# ĞŸÑ€Ğ¾Ğ²ĞµÑ€ĞºĞ° Ğ´Ğ¾ÑÑ‚ÑƒĞ¿Ğ½Ğ¾ÑÑ‚Ğ¸
docker exec clickhouse-01 clickhouse-client --query "SELECT 1"

# ĞŸÑ€Ğ¾Ğ²ĞµÑ€ĞºĞ° Ğ¿Ñ€Ğ¾Ñ„Ğ¸Ğ»Ñ dbt
dbt debug --config-dir .
```

#### 2. **ĞÑˆĞ¸Ğ±ĞºĞ¸ ĞºĞ¾Ğ¼Ğ¿Ğ¸Ğ»ÑÑ†Ğ¸Ğ¸**
```bash
# ĞŸÑ€Ğ¾Ğ²ĞµÑ€ĞºĞ° ÑĞ¸Ğ½Ñ‚Ğ°ĞºÑĞ¸ÑĞ°
dbt compile --select model_name

# ĞŸÑ€Ğ¾Ğ²ĞµÑ€ĞºĞ° Ğ·Ğ°Ğ²Ğ¸ÑĞ¸Ğ¼Ğ¾ÑÑ‚ĞµĞ¹
dbt deps
```

#### 3. **ĞŸÑ€Ğ¾Ğ±Ğ»ĞµĞ¼Ñ‹ Ñ Ğ¿Ñ€Ğ¾Ğ¸Ğ·Ğ²Ğ¾Ğ´Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ¾ÑÑ‚ÑŒÑ**
```sql
-- ĞĞ½Ğ°Ğ»Ğ¸Ğ· Ğ·Ğ°Ğ¿Ñ€Ğ¾ÑĞ¾Ğ² Ğ² ClickHouse
SELECT 
  query,
  query_duration_ms,
  memory_usage
FROM system.query_log
WHERE type = 'QueryFinish'
ORDER BY query_duration_ms DESC
LIMIT 10;
```

### Ğ”Ğ¸Ğ°Ğ³Ğ½Ğ¾ÑÑ‚Ğ¸ĞºĞ°

#### 1. **Ğ›Ğ¾Ğ³Ğ¸ dbt**
```bash
# ĞŸĞ¾Ğ´Ñ€Ğ¾Ğ±Ğ½Ñ‹Ğµ Ğ»Ğ¾Ğ³Ğ¸
dbt run --verbose

# Ğ›Ğ¾Ğ³Ğ¸ Ğ² Ñ„Ğ°Ğ¹Ğ»
dbt run --log-file dbt.log
```

#### 2. **Ğ›Ğ¾Ğ³Ğ¸ ClickHouse**
```bash
# Ğ›Ğ¾Ğ³Ğ¸ Ğ·Ğ°Ğ¿Ñ€Ğ¾ÑĞ¾Ğ²
docker exec clickhouse-01 tail -f /var/log/clickhouse-server/clickhouse-server.log

# Ğ›Ğ¾Ğ³Ğ¸ Ğ¾ÑˆĞ¸Ğ±Ğ¾Ğº
docker exec clickhouse-01 tail -f /var/log/clickhouse-server/clickhouse-server.err.log
```

## ğŸ“ˆ ĞœĞ¾Ğ½Ğ¸Ñ‚Ğ¾Ñ€Ğ¸Ğ½Ğ³ Ğ¸ Ğ¼ĞµÑ‚Ñ€Ğ¸ĞºĞ¸

### ĞšĞ»ÑÑ‡ĞµĞ²Ñ‹Ğµ Ğ¼ĞµÑ‚Ñ€Ğ¸ĞºĞ¸

- **Ğ’Ñ€ĞµĞ¼Ñ Ğ²Ñ‹Ğ¿Ğ¾Ğ»Ğ½ĞµĞ½Ğ¸Ñ** Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹
- **ĞšĞ¾Ğ»Ğ¸Ñ‡ĞµÑÑ‚Ğ²Ğ¾ Ğ·Ğ°Ğ¿Ğ¸ÑĞµĞ¹** Ğ² Ñ‚Ğ°Ğ±Ğ»Ğ¸Ñ†Ğ°Ñ…
- **ĞšĞ°Ñ‡ĞµÑÑ‚Ğ²Ğ¾ Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ…** (Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ñ‹ Ñ‚ĞµÑÑ‚Ğ¾Ğ²)
- **Ğ˜ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ Ñ€ĞµÑÑƒÑ€ÑĞ¾Ğ²** ClickHouse

### ĞĞ»ĞµÑ€Ñ‚Ñ‹

- **Ğ¡Ğ±Ğ¾Ğ¸ Ğ² Ğ¿Ğ°Ğ¹Ğ¿Ğ»Ğ°Ğ¹Ğ½Ğ°Ñ…** dbt
- **ĞÑˆĞ¸Ğ±ĞºĞ¸ Ñ‚ĞµÑÑ‚Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ**
- **Ğ”Ğ¾Ğ»Ğ³Ğ¾Ğµ Ğ²Ñ‹Ğ¿Ğ¾Ğ»Ğ½ĞµĞ½Ğ¸Ğµ** Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹
- **ĞŸÑ€Ğ¾Ğ±Ğ»ĞµĞ¼Ñ‹ Ñ ĞºĞ°Ñ‡ĞµÑÑ‚Ğ²Ğ¾Ğ¼** Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ…

## ğŸ”® ĞŸĞ»Ğ°Ğ½Ñ‹ Ñ€Ğ°Ğ·Ğ²Ğ¸Ñ‚Ğ¸Ñ

### ĞšÑ€Ğ°Ñ‚ĞºĞ¾ÑÑ€Ğ¾Ñ‡Ğ½Ñ‹Ğµ (3-6 Ğ¼ĞµÑÑÑ†ĞµĞ²)
- [ ] ĞĞ²Ñ‚Ğ¾Ğ¼Ğ°Ñ‚Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ Ñ‚ĞµÑÑ‚Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ…
- [ ] Ğ£Ğ»ÑƒÑ‡ÑˆĞµĞ½Ğ¸Ğµ Ğ´Ğ¾ĞºÑƒĞ¼ĞµĞ½Ñ‚Ğ°Ñ†Ğ¸Ğ¸
- [ ] ĞĞ¿Ñ‚Ğ¸Ğ¼Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ Ğ¿Ñ€Ğ¾Ğ¸Ğ·Ğ²Ğ¾Ğ´Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ¾ÑÑ‚Ğ¸

### Ğ¡Ñ€ĞµĞ´Ğ½ĞµÑÑ€Ğ¾Ñ‡Ğ½Ñ‹Ğµ (6-12 Ğ¼ĞµÑÑÑ†ĞµĞ²)
- [ ] Machine Learning Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸
- [ ] Real-time Ñ‚Ñ€Ğ°Ğ½ÑÑ„Ğ¾Ñ€Ğ¼Ğ°Ñ†Ğ¸Ğ¸
- [ ] Ğ Ğ°ÑÑˆĞ¸Ñ€ĞµĞ½Ğ½Ñ‹Ğµ Ğ¼Ğ°ĞºÑ€Ğ¾ÑÑ‹

### Ğ”Ğ¾Ğ»Ğ³Ğ¾ÑÑ€Ğ¾Ñ‡Ğ½Ñ‹Ğµ (1+ Ğ³Ğ¾Ğ´)
- [ ] AI-powered data quality
- [ ] Automated data lineage
- [ ] Multi-database support

## ğŸ“š Ğ”Ğ¾Ğ¿Ğ¾Ğ»Ğ½Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ñ‹Ğµ Ñ€ĞµÑÑƒÑ€ÑÑ‹

- [dbt Documentation](https://docs.getdbt.com/)
- [ClickHouse Documentation](https://clickhouse.com/docs/)
- [dbt-utils Package](https://hub.getdbt.com/dbt-labs/dbt_utils/)
- [dbt Best Practices](https://docs.getdbt.com/guides/best-practices)
