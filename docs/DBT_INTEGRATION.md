# üîó –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è dbt —Å ClickHouse

## –û–±–∑–æ—Ä

ClickHouse EnergyHub –∏—Å–ø–æ–ª—å–∑—É–µ—Ç **dbt (data build tool)** –¥–ª—è —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏–∏ –¥–∞–Ω–Ω—ã—Ö –≤ ClickHouse. –≠—Ç–∞ –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è –æ–±–µ—Å–ø–µ—á–∏–≤–∞–µ—Ç –¥–µ–∫–ª–∞—Ä–∞—Ç–∏–≤–Ω—ã–π –ø–æ–¥—Ö–æ–¥ –∫ —Å–æ–∑–¥–∞–Ω–∏—é –º–æ–¥–µ–ª–µ–π –¥–∞–Ω–Ω—ã—Ö, –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∏ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—é.

## üèóÔ∏è –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏

### –ö–æ–º–ø–æ–Ω–µ–Ω—Ç—ã —Å–∏—Å—Ç–µ–º—ã

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   ClickHouse    ‚îÇ    ‚îÇ      dbt        ‚îÇ    ‚îÇ     Airflow     ‚îÇ
‚îÇ                 ‚îÇ    ‚îÇ                 ‚îÇ    ‚îÇ                 ‚îÇ
‚îÇ ‚Ä¢ Raw Tables    ‚îÇ‚óÑ‚îÄ‚îÄ‚îÄ‚î§ ‚Ä¢ Models        ‚îÇ‚óÑ‚îÄ‚îÄ‚îÄ‚î§ ‚Ä¢ DAGs          ‚îÇ
‚îÇ ‚Ä¢ ODS Tables    ‚îÇ    ‚îÇ ‚Ä¢ Tests         ‚îÇ    ‚îÇ ‚Ä¢ Scheduling    ‚îÇ
‚îÇ ‚Ä¢ DDS Tables    ‚îÇ    ‚îÇ ‚Ä¢ Sources       ‚îÇ    ‚îÇ ‚Ä¢ Monitoring    ‚îÇ
‚îÇ ‚Ä¢ CDM Tables    ‚îÇ    ‚îÇ ‚Ä¢ Macros        ‚îÇ    ‚îÇ ‚Ä¢ Logs          ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### –ü–æ—Ç–æ–∫ –¥–∞–Ω–Ω—ã—Ö

```
1. ClickHouse Tables ‚Üí 2. dbt Sources ‚Üí 3. dbt Models ‚Üí 4. ClickHouse Tables
     ‚Üì                       ‚Üì              ‚Üì              ‚Üì
  Data Storage         Metadata        Transformation   Processed Data
```

## üìÅ –°—Ç—Ä—É–∫—Ç—É—Ä–∞ –ø—Ä–æ–µ–∫—Ç–∞ dbt

```
dbt/
‚îú‚îÄ‚îÄ dbt_project.yml          # –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –ø—Ä–æ–µ–∫—Ç–∞
‚îú‚îÄ‚îÄ profiles.yml             # –ü—Ä–æ—Ñ–∏–ª–∏ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è
‚îú‚îÄ‚îÄ packages.yml             # –ó–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏
‚îú‚îÄ‚îÄ models/                  # –ú–æ–¥–µ–ª–∏ –¥–∞–Ω–Ω—ã—Ö
‚îÇ   ‚îú‚îÄ‚îÄ sources.yml          # –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤
‚îÇ   ‚îú‚îÄ‚îÄ raw/                 # –ú–æ–¥–µ–ª–∏ –¥–ª—è raw —Å–ª–æ—è
‚îÇ   ‚îú‚îÄ‚îÄ ods/                 # –ú–æ–¥–µ–ª–∏ –¥–ª—è ODS —Å–ª–æ—è
‚îÇ   ‚îú‚îÄ‚îÄ dds/                 # –ú–æ–¥–µ–ª–∏ –¥–ª—è DDS —Å–ª–æ—è
‚îÇ   ‚îî‚îÄ‚îÄ cdm/                 # –ú–æ–¥–µ–ª–∏ –¥–ª—è CDM —Å–ª–æ—è
‚îú‚îÄ‚îÄ tests/                   # –ö–∞—Å—Ç–æ–º–Ω—ã–µ —Ç–µ—Å—Ç—ã
‚îú‚îÄ‚îÄ macros/                  # –ú–∞–∫—Ä–æ—Å—ã
‚îú‚îÄ‚îÄ seeds/                   # –°—Ç–∞—Ç–∏—á–µ—Å–∫–∏–µ –¥–∞–Ω–Ω—ã–µ
‚îî‚îÄ‚îÄ target/                  # –°–∫–æ–º–ø–∏–ª–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –º–æ–¥–µ–ª–∏
```

## ‚öôÔ∏è –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è

### dbt_project.yml

```yaml
name: 'clickhouse_energyhub'
version: '1.0.0'
config-version: 2

profile: 'clickhouse_energyhub'

model-paths: ["models"]
analysis-paths: ["analyses"]
test-paths: ["tests"]
seed-paths: ["seeds"]
macro-paths: ["macros"]
snapshot-paths: ["snapshots"]

target-path: "target"
clean-targets:
  - "target"
  - "dbt_packages"

models:
  clickhouse_energyhub:
    materialized: table
    raw:
      materialized: table
      tags: ["raw"]
    ods:
      materialized: table
      tags: ["ods"]
    dds:
      materialized: table
      tags: ["dds"]
    cdm:
      materialized: table
      tags: ["cdm"]

vars:
  clickhouse_database: "default"
  clickhouse_cluster: "clickhouse_cluster"
```

### profiles.yml

```yaml
clickhouse_energyhub:
  target: dev
  outputs:
    dev:
      type: clickhouse
      host: clickhouse-01
      port: 9000
      user: principalwater
      password: UnixSpace@11.
      database: default
      schema: default
      threads: 4
      keepalives_idle: 0
      connect_timeout: 10
      send_receive_timeout: 300
      sync_request_timeout: 5
      compression: True
      secure: False
      verify: False
      client_name: dbt
      settings:
        optimize_aggregation_in_order: 1
        max_threads: 8
        max_memory_usage: 8589934592
```

### packages.yml

```yaml
packages:
  - package: dbt-labs/dbt_utils
    version: 1.1.1
  - package: dbt-labs/audit_helper
    version: 0.9.0
  - package: metaplane/dbt_expectations
    version: 0.10.4
  - package: godatadriven/dbt_date
    version: 0.10.1
```

## üèóÔ∏è –ú–æ–¥–µ–ª–∏ –¥–∞–Ω–Ω—ã—Ö

### –¢–∏–ø—ã –º–æ–¥–µ–ª–µ–π

#### 1. **Raw Models** (–°—ã—Ä—ã–µ –¥–∞–Ω–Ω—ã–µ)
```sql
-- models/raw/raw_river_flow.sql
{{
  config(
    materialized='table',
    tags=['raw', 'river_flow']
  )
}}

SELECT 
  ges_name,
  timestamp,
  river_name,
  water_level_m,
  flow_rate_m3_s,
  power_output_mw,
  now() as loaded_at
FROM {{ source('raw', 'river_flow') }}
WHERE timestamp >= '{{ var("start_date", "2020-01-01") }}'
```

#### 2. **ODS Models** (–û–ø–µ—Ä–∞—Ü–∏–æ–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ)
```sql
-- models/ods/ods_river_flow.sql
{{
  config(
    materialized='table',
    tags=['ods', 'river_flow']
  )
}}

SELECT 
  ges_name,
  timestamp,
  river_name,
  CAST(water_level_m AS Float64) as water_level_m,
  CAST(flow_rate_m3_s AS Float64) as flow_rate_m3_s,
  CAST(power_output_mw AS Float64) as power_output_mw,
  now() as processed_at
FROM {{ ref('raw_river_flow') }}
WHERE ges_name IS NOT NULL
  AND timestamp IS NOT NULL
  AND river_name IS NOT NULL
```

#### 3. **DDS Models** (–î–µ—Ç–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ)
```sql
-- models/dds/dds_river_flow_clean.sql
{{
  config(
    materialized='table',
    tags=['dds', 'river_flow', 'clean']
  )
}}

WITH deduplicated_river_flow AS (
  SELECT 
    ges_name,
    timestamp,
    river_name,
    water_level_m,
    flow_rate_m3_s,
    power_output_mw,
    ROW_NUMBER() OVER (
      PARTITION BY ges_name, timestamp, river_name 
      ORDER BY timestamp DESC
    ) as rn
  FROM {{ source('raw', 'river_flow') }}
  WHERE ges_name IS NOT NULL 
    AND timestamp IS NOT NULL 
    AND river_name IS NOT NULL
)

SELECT 
  ges_name,
  timestamp,
  river_name,
  water_level_m,
  flow_rate_m3_s,
  power_output_mw,
  now() as inserted_at,
  'dbt_clean' as source
FROM deduplicated_river_flow
WHERE rn = 1
```

#### 4. **CDM Models** (–ö–æ–Ω—Ñ–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ)
```sql
-- models/cdm/cdm_daily_river_flow_summary.sql
{{
  config(
    materialized='table',
    tags=['cdm', 'river_flow', 'summary']
  )
}}

SELECT 
  toDate(timestamp) as date,
  ges_name,
  river_name,
  COUNT(*) as record_count,
  AVG(water_level_m) as avg_water_level,
  AVG(flow_rate_m3_s) as avg_flow_rate,
  AVG(power_output_mw) as avg_power_output,
  MAX(water_level_m) as max_water_level,
  MIN(water_level_m) as min_water_level,
  now() as calculated_at
FROM {{ ref('dds_river_flow_clean') }}
GROUP BY toDate(timestamp), ges_name, river_name
ORDER BY date DESC, ges_name, river_name
```

### View Models

```sql
-- models/dds/dds_river_flow_view.sql
{{
  config(
    materialized='view',
    tags=['dds', 'river_flow', 'view']
  )
}}

SELECT 
  ges_name,
  timestamp,
  river_name,
  water_level_m,
  flow_rate_m3_s,
  power_output_mw,
  inserted_at,
  source
FROM {{ ref('dds_river_flow_clean') }}
WHERE inserted_at >= now() - INTERVAL 30 DAY
```

## üß™ –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ

### –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–µ —Ç–µ—Å—Ç—ã

#### 1. **Generic Tests** (–í—Å—Ç—Ä–æ–µ–Ω–Ω—ã–µ —Ç–µ—Å—Ç—ã)
```yaml
# models/dds/schema.yml
version: 2

models:
  - name: dds_river_flow_clean
    description: "–û—á–∏—â–µ–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ river_flow –±–µ–∑ –¥—É–±–ª–µ–π"
    columns:
      - name: ges_name
        description: "–ù–∞–∑–≤–∞–Ω–∏–µ –ì–≠–°"
        tests:
          - not_null
          - dbt_utils.not_empty_string
      
      - name: timestamp
        description: "–í—Ä–µ–º–µ–Ω–Ω–∞—è –º–µ—Ç–∫–∞"
        tests:
          - not_null
      
      - name: water_level_m
        description: "–£—Ä–æ–≤–µ–Ω—å –≤–æ–¥—ã –≤ –º–µ—Ç—Ä–∞—Ö"
        tests:
          - not_null
          - dbt_utils.accepted_range:
              min_value: 0
              max_value: 1000
```

#### 2. **Custom Tests** (–ö–∞—Å—Ç–æ–º–Ω—ã–µ —Ç–µ—Å—Ç—ã)
```sql
-- tests/test_no_duplicates.sql
SELECT 
  ges_name,
  timestamp,
  river_name,
  COUNT(*) as record_count
FROM {{ ref('dds_river_flow_clean') }}
GROUP BY ges_name, timestamp, river_name
HAVING COUNT(*) > 1
```

#### 3. **Data Tests** (–¢–µ—Å—Ç—ã –¥–∞–Ω–Ω—ã—Ö)
```sql
-- tests/test_data_quality.sql
SELECT 
  'water_level_out_of_range' as test_name,
  COUNT(*) as failed_records
FROM {{ ref('dds_river_flow_clean') }}
WHERE water_level_m < 0 OR water_level_m > 1000

UNION ALL

SELECT 
  'flow_rate_out_of_range' as test_name,
  COUNT(*) as failed_records
FROM {{ ref('dds_river_flow_clean') }}
WHERE flow_rate_m3_s < 0 OR flow_rate_m3_s > 10000
```

### –ó–∞–ø—É—Å–∫ —Ç–µ—Å—Ç–æ–≤

```bash
# –í—Å–µ —Ç–µ—Å—Ç—ã
dbt test

# –¢–µ—Å—Ç—ã –¥–ª—è –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–π –º–æ–¥–µ–ª–∏
dbt test --select dds_river_flow_clean

# –¢–µ—Å—Ç—ã –¥–ª—è –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–≥–æ —Ç–µ–≥–∞
dbt test --select tag:clean

# –ö–∞—Å—Ç–æ–º–Ω—ã–µ —Ç–µ—Å—Ç—ã
dbt test --select test_no_duplicates
```

## üîÑ –ò—Å—Ç–æ—á–Ω–∏–∫–∏ –¥–∞–Ω–Ω—ã—Ö

### –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ sources.yml

–°–∏—Å—Ç–µ–º–∞ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –æ–±–Ω–æ–≤–ª—è–µ—Ç `sources.yml` –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ç–∞–±–ª–∏—Ü –≤ ClickHouse:

```yaml
# models/sources.yml (–∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –≥–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç—Å—è)
version: 2

sources:
  - name: raw
    description: "Tables from raw database"
    database: raw
    schema: raw
    tables:
      - name: river_flow
        description: "Raw river flow data"
        columns:
          - name: ges_name
            description: "Name of the hydroelectric power station"
            tests:
              - not_null
          - name: timestamp
            description: "Measurement timestamp"
            tests:
              - not_null
          # ... –¥—Ä—É–≥–∏–µ –∫–æ–ª–æ–Ω–∫–∏
```

### –†—É—á–Ω–æ–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤

```yaml
# models/sources.yml (—Ä—É—á–Ω–æ–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ)
version: 2

sources:
  - name: external_api
    description: "External API data sources"
    tables:
      - name: weather_data
        description: "Weather information from external API"
        columns:
          - name: timestamp
            description: "Weather measurement time"
            tests:
              - not_null
          - name: temperature
            description: "Temperature in Celsius"
            tests:
              - not_null
              - dbt_utils.accepted_range:
                  min_value: -50
                  max_value: 60
```

## üéØ –ú–∞–∫—Ä–æ—Å—ã

### –ü–æ–ª–µ–∑–Ω—ã–µ –º–∞–∫—Ä–æ—Å—ã –¥–ª—è ClickHouse

#### 1. **–ü–∞—Ä—Ç–∏—Ü–∏–æ–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ –ø–æ –≤—Ä–µ–º–µ–Ω–∏**
```sql
-- macros/partition_by_time.sql
{% macro partition_by_time(column_name) %}
  PARTITION BY toYYYYMM({{ column_name }})
{% endmacro %}
```

#### 2. **–û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –¥–ª—è ClickHouse**
```sql
-- macros/clickhouse_optimize.sql
{% macro clickhouse_optimize() %}
  OPTIMIZE TABLE {{ this }} FINAL
{% endmacro %}
```

#### 3. **–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –¥–∞—Ç**
```sql
-- macros/generate_date_spine.sql
{% macro generate_date_spine(datepart, start_date, end_date) %}
  SELECT 
    toDate(date) as date
  FROM (
    SELECT 
      toDate('{{ start_date }}') + INTERVAL number DAY as date
    FROM numbers(
      dateDiff('day', '{{ start_date }}', '{{ end_date }}') + 1
    )
  )
{% endmacro %}
```

### –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –º–∞–∫—Ä–æ—Å–æ–≤

```sql
-- models/cdm/cdm_daily_summary.sql
{{
  config(
    materialized='table',
    tags=['cdm', 'summary']
  )
}}

SELECT 
  d.date,
  COUNT(r.record_id) as record_count
FROM {{ generate_date_spine('day', '2020-01-01', '2024-12-31') }} d
LEFT JOIN {{ ref('raw_records') }} r ON toDate(r.timestamp) = d.date
GROUP BY d.date
ORDER BY d.date
```

## üìä –î–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è

### –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏

```bash
# –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏
dbt docs generate

# –ó–∞–ø—É—Å–∫ –≤–µ–±-—Å–µ—Ä–≤–µ—Ä–∞ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏
dbt docs serve --port 8080
```

### –°—Ç—Ä—É–∫—Ç—É—Ä–∞ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏

```
üìö dbt Documentation
‚îú‚îÄ‚îÄ üè† Home
‚îú‚îÄ‚îÄ üìÅ Models
‚îÇ   ‚îú‚îÄ‚îÄ Raw Layer
‚îÇ   ‚îú‚îÄ‚îÄ ODS Layer
‚îÇ   ‚îú‚îÄ‚îÄ DDS Layer
‚îÇ   ‚îî‚îÄ‚îÄ CDM Layer
‚îú‚îÄ‚îÄ üîó Sources
‚îú‚îÄ‚îÄ üß™ Tests
‚îú‚îÄ‚îÄ üìä Lineage Graph
‚îî‚îÄ‚îÄ üìà DAG View
```

## üöÄ –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è —Å Airflow

### DAG –¥–ª—è dbt

```python
# airflow/dags/dbt_pipeline.py
from airflow import DAG
from airflow.operators.bash import BashOperator
from datetime import datetime, timedelta

default_args = {
    'owner': 'energy-hub',
    'depends_on_past': False,
    'start_date': datetime(2025, 1, 1),
    'email_on_failure': False,
    'email_on_retry': False,
    'retries': 2,
    'retry_delay': timedelta(minutes=5),
}

dag = DAG(
    'dbt_pipeline',
    default_args=default_args,
    description='dbt data transformation pipeline',
    schedule='0 */2 * * *',  # –ö–∞–∂–¥—ã–µ 2 —á–∞—Å–∞
    catchup=False,
)

# –ó–∞–¥–∞—á–∏ dbt
run_models = BashOperator(
    task_id='run_dbt_models',
    bash_command='cd /opt/airflow/dbt && dbt run',
    dag=dag,
)

run_tests = BashOperator(
    task_id='run_dbt_tests',
    bash_command='cd /opt/airflow/dbt && dbt test',
    dag=dag,
)

generate_docs = BashOperator(
    task_id='generate_dbt_docs',
    bash_command='cd /opt/airflow/dbt && dbt docs generate',
    dag=dag,
)

# –ó–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏
run_models >> run_tests >> generate_docs
```

### –ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –≤ Airflow

- **–õ–æ–≥–∏ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è** –∫–∞–∂–¥–æ–π dbt –∫–æ–º–∞–Ω–¥—ã
- **–í—Ä–µ–º—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è** –º–æ–¥–µ–ª–µ–π
- **–°—Ç–∞—Ç—É—Å —Ç–µ—Å—Ç–æ–≤** (PASS/FAIL)
- **–£–≤–µ–¥–æ–º–ª–µ–Ω–∏—è** –æ–± –æ—à–∏–±–∫–∞—Ö

## üîß –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏

### ClickHouse —Å–ø–µ—Ü–∏—Ñ–∏—á–Ω—ã–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏

#### 1. **–ü–∞—Ä—Ç–∏—Ü–∏–æ–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ**
```sql
-- –û–ø—Ç–∏–º–∞–ª—å–Ω–æ–µ –ø–∞—Ä—Ç–∏—Ü–∏–æ–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ –¥–ª—è –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ä—è–¥–æ–≤
PARTITION BY toYYYYMM(timestamp)
ORDER BY (timestamp, entity_id)
```

#### 2. **–ò–Ω–¥–µ–∫—Å—ã**
```sql
-- –°–æ–∑–¥–∞–Ω–∏–µ –∏–Ω–¥–µ–∫—Å–æ–≤ –¥–ª—è —á–∞—Å—Ç–æ –∏—Å–ø–æ–ª—å–∑—É–µ–º—ã—Ö –∫–æ–ª–æ–Ω–æ–∫
ALTER TABLE dds_river_flow_clean 
ADD INDEX idx_ges_name ges_name TYPE bloom_filter GRANULARITY 1;
```

#### 3. **–ú–∞—Ç–µ—Ä–∏–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏—è**
```sql
-- –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ –∞–≥—Ä–µ–≥–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
CREATE MATERIALIZED VIEW cdm_daily_summary_mv
ENGINE = SummingMergeTree()
PARTITION BY toYYYYMM(date)
ORDER BY (date, ges_name)
AS SELECT 
    toDate(timestamp) as date,
    ges_name,
    COUNT(*) as record_count,
    AVG(water_level_m) as avg_water_level
FROM dds_river_flow_clean
GROUP BY date, ges_name;
```

### dbt –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏

#### 1. **–ò–Ω–∫—Ä–µ–º–µ–Ω—Ç–∞–ª—å–Ω—ã–µ –º–æ–¥–µ–ª–∏**
```sql
-- models/dds/dds_river_flow_incremental.sql
{{
  config(
    materialized='incremental',
    unique_key='id',
    incremental_strategy='delete+insert'
  )
}}

SELECT 
  id,
  ges_name,
  timestamp,
  -- ... –¥—Ä—É–≥–∏–µ –∫–æ–ª–æ–Ω–∫–∏
FROM {{ source('raw', 'river_flow') }}

{% if is_incremental() %}
  WHERE timestamp > (SELECT MAX(timestamp) FROM {{ this }})
{% endif %}
```

#### 2. **–ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ–µ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–µ**
```yaml
# dbt_project.yml
threads: 8  # –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω—ã—Ö –ø–æ—Ç–æ–∫–æ–≤
```

## üö® –£—Å—Ç—Ä–∞–Ω–µ–Ω–∏–µ –Ω–µ–ø–æ–ª–∞–¥–æ–∫

### –ß–∞—Å—Ç—ã–µ –ø—Ä–æ–±–ª–µ–º—ã

#### 1. **–û—à–∏–±–∫–∏ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –∫ ClickHouse**
```bash
# –ü—Ä–æ–≤–µ—Ä–∫–∞ –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç–∏
docker exec clickhouse-01 clickhouse-client --query "SELECT 1"

# –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø—Ä–æ—Ñ–∏–ª—è dbt
dbt debug --config-dir .
```

#### 2. **–û—à–∏–±–∫–∏ –∫–æ–º–ø–∏–ª—è—Ü–∏–∏**
```bash
# –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å–∏–Ω—Ç–∞–∫—Å–∏—Å–∞
dbt compile --select model_name

# –ü—Ä–æ–≤–µ—Ä–∫–∞ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π
dbt deps
```

#### 3. **–ü—Ä–æ–±–ª–µ–º—ã —Å –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å—é**
```sql
-- –ê–Ω–∞–ª–∏–∑ –∑–∞–ø—Ä–æ—Å–æ–≤ –≤ ClickHouse
SELECT 
  query,
  query_duration_ms,
  memory_usage
FROM system.query_log
WHERE type = 'QueryFinish'
ORDER BY query_duration_ms DESC
LIMIT 10;
```

### –î–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∞

#### 1. **–õ–æ–≥–∏ dbt**
```bash
# –ü–æ–¥—Ä–æ–±–Ω—ã–µ –ª–æ–≥–∏
dbt run --verbose

# –õ–æ–≥–∏ –≤ —Ñ–∞–π–ª
dbt run --log-file dbt.log
```

#### 2. **–õ–æ–≥–∏ ClickHouse**
```bash
# –õ–æ–≥–∏ –∑–∞–ø—Ä–æ—Å–æ–≤
docker exec clickhouse-01 tail -f /var/log/clickhouse-server/clickhouse-server.log

# –õ–æ–≥–∏ –æ—à–∏–±–æ–∫
docker exec clickhouse-01 tail -f /var/log/clickhouse-server/clickhouse-server.err.log
```

## üìà –ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –∏ –º–µ—Ç—Ä–∏–∫–∏

### –ö–ª—é—á–µ–≤—ã–µ –º–µ—Ç—Ä–∏–∫–∏

- **–í—Ä–µ–º—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è** –º–æ–¥–µ–ª–µ–π
- **–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∑–∞–ø–∏—Å–µ–π** –≤ —Ç–∞–±–ª–∏—Ü–∞—Ö
- **–ö–∞—á–µ—Å—Ç–≤–æ –¥–∞–Ω–Ω—ã—Ö** (—Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã —Ç–µ—Å—Ç–æ–≤)
- **–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ —Ä–µ—Å—É—Ä—Å–æ–≤** ClickHouse

### –ê–ª–µ—Ä—Ç—ã

- **–°–±–æ–∏ –≤ –ø–∞–π–ø–ª–∞–π–Ω–∞—Ö** dbt
- **–û—à–∏–±–∫–∏ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è**
- **–î–æ–ª–≥–æ–µ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–µ** –º–æ–¥–µ–ª–µ–π
- **–ü—Ä–æ–±–ª–µ–º—ã —Å –∫–∞—á–µ—Å—Ç–≤–æ–º** –¥–∞–Ω–Ω—ã—Ö

## üîÆ –ü–ª–∞–Ω—ã —Ä–∞–∑–≤–∏—Ç–∏—è

### –ö—Ä–∞—Ç–∫–æ—Å—Ä–æ—á–Ω—ã–µ (3-6 –º–µ—Å—è—Ü–µ–≤)
- [ ] –ê–≤—Ç–æ–º–∞—Ç–∏–∑–∞—Ü–∏—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö
- [ ] –£–ª—É—á—à–µ–Ω–∏–µ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏
- [ ] –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏

### –°—Ä–µ–¥–Ω–µ—Å—Ä–æ—á–Ω—ã–µ (6-12 –º–µ—Å—è—Ü–µ–≤)
- [ ] Machine Learning –º–æ–¥–µ–ª–∏
- [ ] Real-time —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏–∏
- [ ] –†–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–µ –º–∞–∫—Ä–æ—Å—ã

### –î–æ–ª–≥–æ—Å—Ä–æ—á–Ω—ã–µ (1+ –≥–æ–¥)
- [ ] AI-powered data quality
- [ ] Automated data lineage
- [ ] Multi-database support

## üìö –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ —Ä–µ—Å—É—Ä—Å—ã

- [dbt Documentation](https://docs.getdbt.com/)
- [ClickHouse Documentation](https://clickhouse.com/docs/)
- [dbt-utils Package](https://hub.getdbt.com/dbt-labs/dbt_utils/)
- [dbt Best Practices](https://docs.getdbt.com/guides/best-practices)
